## Project: Optimization Techniques in Convex Functions

Spearheaded a comprehensive project on "Optimization Techniques in Convex Functions," delving into root-finding algorithms, Gradient Descent, and Linear Programming.

### Key Highlights

- Developed and implemented dichotomous, Newton-Raphson, and Gradient Descent algorithms for efficient root-finding in convex functions.
- Explored the impact of learning rates in Gradient Descent, applying the method to one-dimensional problems and aligning results with other root-finding techniques.
- Extended the study to linear programming, utilizing the Simplex method to solve problems with linear constraints.
- Leveraged libraries like NumPy, SciPy, and matplotlib for technical implementations.
- Published findings and insights from the project to contribute to the knowledge base of the field.

### Implemented Algorithms

1. **Dichotomous Algorithm:**
   - Efficient root-finding algorithm for convex functions.

2. **Newton-Raphson Algorithm:**
   - Iterative method for finding roots in convex functions.

3. **Gradient Descent:**
   - Implemented Gradient Descent algorithms, exploring the impact of learning rates on optimization.

4. **Linear Programming with Simplex Method:**
   - Applied the Simplex method for solving linear programming problems with linear constraints.

### Libraries Used

- NumPy
- SciPy
- matplotlib
